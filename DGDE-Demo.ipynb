{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80281a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,input_size=1000,hidden_size=100,output_size=10):\n",
    "        super(NeuralNet,self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=input_size, out_features=hidden_size, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_size, out_features=output_size, bias=True)\n",
    "    def forward(self,X):\n",
    "        FX = F.relu(self.fc1(X)) # hidden layer activation features\n",
    "        prob = F.softmax(self.fc2(FX),dim=1) # probability output\n",
    "        return FX,prob\n",
    "\n",
    "\n",
    "class DGDE:\n",
    "    \"\"\"\n",
    "    The batch size per iteration is batch_size * num_class * num_domain\n",
    "    \"\"\"\n",
    "    def __init__(self,input_size=1000,hidden_size=100,output_size=10,seed=1000,device=torch.device('cpu'),\n",
    "                 epoch=200,lamda=1e-3,gamma=100,sigma=None,batch_size=4,lr=1e-3,log=True):\n",
    "        args_values = locals()\n",
    "        args_values.pop(\"self\")\n",
    "        for arg,value in args_values.items():\n",
    "            setattr(self,arg,value)\n",
    "            \n",
    "    def fit(self,X_list,y_list,Xt,yt):\n",
    "        torch.manual_seed(self.seed)\n",
    "        net = NeuralNet(input_size=self.input_size,hidden_size=self.hidden_size,output_size=self.output_size).to(self.device)\n",
    "        optimizer = optim.SGD(params=net.parameters(),lr=self.lr,momentum=0.9)\n",
    "        \n",
    "        for epoch in range(self.epoch):\n",
    "            dataset_loaders, l = [], 0\n",
    "            for Xs,ys in zip(X_list,y_list):\n",
    "                for i,counts in zip(*np.unique(ys,return_counts=True)):\n",
    "                    dataset = np.hstack((Xs[ys==i],ys[ys==i][:,None],l * np.ones((counts,1))))\n",
    "                    dataset_loaders.append(torch.utils.data.DataLoader(dataset=torch.tensor(dataset),batch_size=self.batch_size,shuffle=True,drop_last=True))\n",
    "                l = l + 1\n",
    "\n",
    "            train_err,m_train = 0.0, 0.0\n",
    "\n",
    "            for batches in zip(*dataset_loaders):\n",
    "                Xyl = torch.cat(batches,dim=0)\n",
    "                X,y,l = Xyl[:,:-2].to(self.device,torch.float32),Xyl[:,-2].to(self.device,torch.int64),Xyl[:,-1].to(self.device,torch.int64)\n",
    "\n",
    "                m,domain_label = X.shape[0], torch.unique(l)\n",
    "                FX,prob = net(X)\n",
    "\n",
    "                num_class = prob.shape[1]\n",
    "                negative_log_loss = -torch.mean(torch.sum(torch.log(prob) * F.one_hot(y,num_class),dim=1))        \n",
    "\n",
    "                #=============KLD calculation===========\n",
    "                if self.sigma is None:\n",
    "                    pairwise_dist = torch.cdist(X,X,p=2)**2 \n",
    "                    self.sigma = torch.median(pairwise_dist[pairwise_dist!=0])\n",
    "\n",
    "                Delta = torch.as_tensor(y[:,None]==y,dtype=torch.float64,device=self.device) # construct the label kernel matrix\n",
    "                FX_norm = torch.sum(FX ** 2, axis = -1)\n",
    "                # construct the Gaussian kernel matrix\n",
    "                #https://stackoverflow.com/questions/47271662/what-is-the-fastest-way-to-compute-an-rbf-kernel-in-python\n",
    "                K = torch.exp(-(FX_norm[:,None] + FX_norm[None,:] - 2 * torch.matmul(FX, FX.t())) / self.sigma)\n",
    "                P = K * Delta\n",
    "                invM = torch.inverse(1./ m * torch.matmul(P.t(),P) + self.lamda * torch.eye(m,device=self.device))\n",
    "\n",
    "                alpha = torch.stack([torch.matmul(invM,1. / m * torch.sum(P[l==i],axis=0)) for i in domain_label],dim=1)\n",
    "                Palpha = torch.clamp(torch.matmul(P,alpha),min=1e-8)\n",
    "                ProbM = Palpha / Palpha.sum(axis=1,keepdim=True)\n",
    "\n",
    "                KLD = 0.\n",
    "                for i in domain_label:\n",
    "                    KLD = KLD + torch.mean(torch.log(ProbM[l==i][:,i]))\n",
    "                #======================================\n",
    "\n",
    "                loss = negative_log_loss + self.gamma * KLD\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_err += loss.item() * m\n",
    "                m_train += m\n",
    "\n",
    "            with torch.no_grad():\n",
    "                Xt,yt = torch.as_tensor(Xt,dtype=torch.float32,device=self.device),torch.as_tensor(yt,dtype=torch.int64,device=self.device)    \n",
    "                pred = torch.argmax(net(Xt)[1],dim=1)\n",
    "                correct = torch.sum((pred == yt)).item()\n",
    "                m_test = len(yt)\n",
    "            \n",
    "            if True == self.log:\n",
    "                print('epoch ',epoch,', training error ',train_err / m_train,', test acc. ',(correct / m_test) * 100) \n",
    "        self.net = net\n",
    "        \n",
    "    def score(self,Xt,yt):\n",
    "        with torch.no_grad():\n",
    "            Xt,yt = torch.as_tensor(Xt,dtype=torch.float32,device=self.device),torch.as_tensor(yt,dtype=torch.int64,device=self.device)    \n",
    "            pred = torch.argmax(self.net(Xt)[1],dim=1)\n",
    "            correct = torch.sum((pred == yt)).item()\n",
    "            m_test = len(yt)\n",
    "        return (correct / m_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90e7a2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import numpy.linalg as la\n",
    "from sklearn.preprocessing import scale,LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cbcfcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(tg,domains):\n",
    "    data = sio.loadmat('ILS_PIE/' + tg + '.mat')\n",
    "    Xt,yt = data['features'].astype(np.float64).T,data['labels'].ravel()\n",
    "    yt = LabelEncoder().fit(yt).transform(yt).astype(np.float64)\n",
    "    #Xt = Xt / la.norm(Xt,axis=1,keepdims=True)\n",
    "    #Xt = scale(Xt)\n",
    "    Xt = scale(Xt / Xt.sum(axis=1,keepdims=True))\n",
    "    \n",
    "    Xs_list,ys_list = [],[]\n",
    "    for sc in domains:\n",
    "        if sc != tg:\n",
    "            data = sio.loadmat('ILS_PIE/' + sc + '.mat')\n",
    "            Xs,ys = data['features'].astype(np.float64).T,data['labels'].ravel()\n",
    "            ys = LabelEncoder().fit(ys).transform(ys).astype(np.float64)\n",
    "            #Xs = Xs / la.norm(Xs,axis=1,keepdims=True)\n",
    "            #Xs = scale(Xs)\n",
    "            Xs = scale(Xs / Xs.sum(axis=1,keepdims=True))\n",
    "            Xs_list.append(Xs),ys_list.append(ys)        \n",
    "    \n",
    "    return Xs_list,ys_list,Xt,yt\n",
    "\n",
    "domains = ['C27', 'C09', 'C05', 'C37', 'C25', 'C02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fbda539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.54906987245295\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGDE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C27</th>\n",
       "      <td>99.145299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C09</th>\n",
       "      <td>83.795309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C05</th>\n",
       "      <td>96.233120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C37</th>\n",
       "      <td>88.603989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C25</th>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C02</th>\n",
       "      <td>72.850036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DGDE\n",
       "C27  99.145299\n",
       "C09  83.795309\n",
       "C05  96.233120\n",
       "C37  88.603989\n",
       "C25  66.666667\n",
       "C02  72.850036"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda:0')\n",
    "domcouples = []\n",
    "res = []\n",
    "\n",
    "for tg in domains:\n",
    "    X_list,y_list,Xt,yt = readData(tg,domains)\n",
    "    \n",
    "    dgde = DGDE(input_size=1024,hidden_size=512,output_size=67,seed=0,device=DEVICE,\n",
    "                         epoch=300,lamda=1e-2,gamma=100,sigma=None,batch_size=5,lr=1e-2,log=False)\n",
    "    dgde.fit(X_list,y_list,Xt,yt)\n",
    "    \n",
    "    domcouples.append(tg)\n",
    "    res.append(dgde.score(Xt,yt))\n",
    "result = pd.DataFrame(data=res,index=domcouples, columns=['DGDE'])\n",
    "print(result.values.mean())\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
